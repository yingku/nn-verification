{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from TL4HDR.data.preProcess import get_one_race, get_n_years, normalize_dataset, \\\n",
    "    standarize_dataset, get_dataset\n",
    "from TL4HDR.examples.classify_util import run_mixture_cv, run_one_race_cv, \\\n",
    "    run_unsupervised_transfer_cv, run_supervised_transfer_cv, run_CCSA_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(11111)\n",
    "set_random_seed(11111)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "rn.seed(11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(cancer_type, feature_type, target, years=3, groups=(\"WHITE\", \"BLACK\")):\n",
    "    print (cancer_type, feature_type, target, years)\n",
    "    # dataset = get_dataset_integ(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    dataset = get_dataset(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    if dataset['X'].shape[0] < 10: return None\n",
    "    dataset = standarize_dataset(dataset)\n",
    "    dataset_w = get_one_race(dataset, 'WHITE')\n",
    "    if dataset_w['X'].shape[0] < 5: return None\n",
    "    dataset_w = get_n_years(dataset_w, years)\n",
    "    dataset_b = get_one_race(dataset, 'BLACK')\n",
    "    if dataset_b['X'].shape[0] < 5: return None\n",
    "    dataset_b = get_n_years(dataset_b, years)\n",
    "\n",
    "    dataset_tl = normalize_dataset(dataset)\n",
    "    dataset_tl = get_n_years(dataset_tl, years)\n",
    "\n",
    "    dataset = get_n_years(dataset, years)\n",
    "    k = 200 if 'mRNA' in feature_type or 'methylation' in feature_type else -1\n",
    "\n",
    "    # print(numpy.count_nonzero(numpy.isnan(dataset['X'])))\n",
    "    X, Y, R, y_sub, y_strat = dataset\n",
    "    df = pd.DataFrame(y_strat, columns=['RY'])\n",
    "    df['R'] = R\n",
    "    df['Y'] = Y\n",
    "    print(X.shape)\n",
    "    Dict = df['RY'].value_counts()\n",
    "    print (Dict)\n",
    "    if len(Dict) < 4: return None\n",
    "    Dict = dict(Dict)\n",
    "    print (Dict)\n",
    "    for key in Dict:\n",
    "        print (key, Dict[key])\n",
    "        if Dict[key] < 5:\n",
    "            return None\n",
    "\n",
    "    parametrs_mix = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,'momentum':0.9,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_w = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_b = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':4,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "    parametrs_tl = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20, 'tune_epoch':500,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5, 'tune_lr':0.002,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64], 'tune_batch':10}\n",
    "\n",
    "    parametrs_tl_unsupervised = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.001, 'lr_decay':0.03, 'dropout':0.0, 'n_epochs':100,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [100]}\n",
    "\n",
    "    # parametrs_tl_sa = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "    #                  'learning_rate':0.005, 'lr_decay':0.0, 'dropout':0.5,\n",
    "    #                  'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "\n",
    "    parameters_CCSA = {'fold': 3, 'n_features': k, 'alpha':0.3, 'batch_size':32, 'learning_rate':0.01,\n",
    "                       'hidden_layers': [100], 'dr':0.0, 'momentum':0.0,\n",
    "                       'decay':0.0, 'sample_per_class':2}\n",
    "\n",
    "    print(\"Begin classifier training\")\n",
    "    \n",
    "    seed = 0\n",
    "    df_m, mixture_classifiers = run_mixture_cv(seed, dataset, **parametrs_mix)\n",
    "    df_w, w_classifiers = run_one_race_cv(seed, dataset_w, **parametrs_w)\n",
    "    df_w = df_w.rename(columns={\"Auc\": \"W_ind\"})\n",
    "    df_b, b_classifiers = run_one_race_cv(seed, dataset_b, **parametrs_b)\n",
    "    df_b = df_b.rename(columns={\"Auc\": \"B_ind\"})\n",
    "    \n",
    "    print(\"Supervised transfer\")\n",
    "    df_tl_supervised, supervised_transfer_classifiers = run_supervised_transfer_cv(seed, dataset, **parametrs_tl)\n",
    "    df_tl_supervised = df_tl_supervised.rename(columns={\"TL_Auc\": \"XY_TL\"})\n",
    "\n",
    "    print(\"Unsupervised transfer\")\n",
    "    df_tl_unsupervised, unsupervised_transfer_classifiers = run_unsupervised_transfer_cv(seed, dataset, **parametrs_tl_unsupervised)\n",
    "    df_tl_unsupervised = df_tl_unsupervised.rename(columns={\"TL_Auc\": \"X_TL\"})\n",
    "\n",
    "    print(\"CCSA transfer\")\n",
    "    df_tl, ccsa_transfer_models = run_CCSA_transfer(seed, dataset_tl, **parameters_CCSA)\n",
    "    df_tl = df_tl.rename(columns={\"TL_Auc\": \"CCSA_TL\"})\n",
    "\n",
    "    df1 = pd.concat([df_m, df_w['W_ind'], df_b['B_ind'], df_tl['CCSA_TL'],\n",
    "                    # df_tl_unsupervised['X_TL'],\n",
    "                     df_tl_supervised['XY_TL']],\n",
    "                    sort=False, axis=1)\n",
    "\n",
    "    print(df1)\n",
    "    \n",
    "    return mixture_classifiers, w_classifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BRCA', 'Protein', 'OS', 4)\n",
      "(811, 190)\n",
      "(810, 192)\n",
      "(322, 189)\n",
      "1WHITE    216\n",
      "0WHITE     57\n",
      "1BLACK     39\n",
      "0BLACK     10\n",
      "Name: RY, dtype: int64\n",
      "{'1BLACK': 39, '0WHITE': 57, '1WHITE': 216, '0BLACK': 10}\n",
      "('1BLACK', 39)\n",
      "('0WHITE', 57)\n",
      "('1WHITE', 216)\n",
      "('0BLACK', 10)\n",
      "Begin classifier training\n",
      "Supervised transfer\n",
      "Unsupervised transfer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TL4HDR/model/mlp.py:158: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(corruption_level, default=0.2),\n",
      "TL4HDR/model/mlp.py:159: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(learning_rate, default=0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSA transfer\n",
      "WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 100)          19000       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_1[0][0]                  \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.596153846154.\n",
      "(17,)\n",
      "(17,)\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 100)          19000       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            202         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_2[0][0]                  \n",
      "                                                                 sequential_2[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.358974358974.\n",
      "(16,)\n",
      "(16,)\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 100)          19000       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            202         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_3[0][0]                  \n",
      "                                                                 sequential_3[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.589743589744.\n",
      "(16,)\n",
      "(16,)\n",
      "     A_Auc     B_Auc     W_Auc  folds     W_ind     B_ind   CCSA_TL    XY_TL\n",
      "0  0.70559  0.479487  0.746914      3  0.759422  0.571795  0.458974  0.54359\n"
     ]
    }
   ],
   "source": [
    "mixture_classifiers, w_clasifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models \\\n",
    "    = run_cv('BRCA', 'Protein', 'OS', years=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield layer.W.get_value()\n",
    "\n",
    "\n",
    "def get_biases(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield layer.b.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNet.utils.writeNNet import writeNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = mixture_classifiers[0]\n",
    "\n",
    "weights = list(get_weights(classifier))\n",
    "biases = list(get_biases(classifier))\n",
    "num_inputs = weights[0].shape[1]\n",
    "# TODO: dataset is normalized; confirm that mins, maxes follows from that\n",
    "# Confirm understanding of meaning of ranges, means; writeNNet iterates an extra time compared to my expectations\n",
    "input_mins = [0 for _ in range(num_inputs)]\n",
    "input_maxes = [1 for _ in range(num_inputs)]\n",
    "input_ranges = [1 for _ in range(num_inputs + 1)]\n",
    "# TODO: pull this data from the datasets instead of guessing\n",
    "input_means = [0.5 for _ in range(num_inputs + 1)]\n",
    "\n",
    "writeNNet(weights, biases, input_mins, input_maxes, input_means, input_ranges, \"classifier.nnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
