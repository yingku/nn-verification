{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named data.preProcess",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a21f078f1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreProcess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_one_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_n_years\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandarize_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcga\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_mixture_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_one_race_cv\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mrun_supervised_transfer_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named data.preProcess"
     ]
    }
   ],
   "source": [
    "from data.preProcess import get_one_race, get_n_years, normalize_dataset, standarize_dataset, get_dataset\n",
    "from data.tcga import read_data\n",
    "from examples.classify_util import run_mixture_cv, run_one_race_cv, \\\n",
    "    run_supervised_transfer_cv\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(11111)\n",
    "set_random_seed(11111)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "rn.seed(11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-e7be7ebd0cdc>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-e7be7ebd0cdc>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    df_m = run_mixture_cv(seed, dataset, **parametrs_mix, groups=groups)\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def run_cv(cancer_type, feature_type, target, years=3, groups=(\"WHITE\", \"BLACK\")):\n",
    "\n",
    "    print (cancer_type, feature_type, target, years)\n",
    "    # dataset = read_data(cancer_type, feature_type[0], target, years)\n",
    "    dataset = get_dataset(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=(\"WHITE\", \"BLACK\"))\n",
    "    dataset = standarize_dataset(dataset)\n",
    "    dataset_w = get_one_race(dataset, groups[0])\n",
    "    dataset_w = get_n_years(dataset_w, years)\n",
    "    dataset_b = get_one_race(dataset, groups[1])\n",
    "    dataset_b = get_n_years(dataset_b, years)\n",
    "    dataset = get_n_years(dataset, years)\n",
    "\n",
    "    k = 200 if 'mRNA' in feature_type else -1\n",
    "    X, Y, R, y_sub, y_strat = dataset\n",
    "    df = pd.DataFrame(y_strat, columns=['RY'])\n",
    "    df['R'] = R\n",
    "    df['Y'] = Y\n",
    "    Dict = df['RY'].value_counts()\n",
    "    Dict = dict(Dict)\n",
    "    print (Dict)\n",
    "\n",
    "    parametrs_mix = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,'momentum':0.9,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hiddenLayers': [128, 64]}\n",
    "    parametrs_w = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hiddenLayers': [128, 64]}\n",
    "\n",
    "    parametrs_b = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':4,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hiddenLayers': [128, 64]}\n",
    "\n",
    "    parametrs_tl = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':32, 'tune_epoch':100, 'train_epoch':100,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5, 'tune_lr':0.01,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hiddenLayers': [128, 64], 'tune_batch':10}\n",
    "\n",
    "    res = pd.DataFrame()\n",
    "    for i in range(20):\n",
    "        seed = i\n",
    "        df_m = run_mixture_cv(seed, dataset, **parametrs_mix, groups=groups)\n",
    "        df_w = run_one_race_cv(seed, dataset_w, **parametrs_w)\n",
    "        df_w = df_w.rename(columns={\"Auc\": \"W_ind\"})\n",
    "        df_b = run_one_race_cv(seed, dataset_b, **parametrs_b)\n",
    "        df_b = df_b.rename(columns={\"Auc\": \"A_ind\"})\n",
    "        df_tl = run_supervised_transfer_cv(seed, dataset, **parametrs_tl, groups=groups)\n",
    "        df1 = pd.concat([df_m, df_w['W_ind'], df_b['A_ind'], df_tl['TL_Auc']],\n",
    "                        sort=False, axis=1)\n",
    "\n",
    "        print (df1)\n",
    "        res = res.append(df1)\n",
    "\n",
    "    f_name = 'Result/' + cancer_type + '-AA-EA-' + feature_type[0] + '-' + target + '-' + str(years) + 'YR.xlsx'\n",
    "    res.to_excel(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    run_cv('STAD', 'Protein', 'DSS', years=1, groups=(\"WHITE\", \"ASIAN\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
