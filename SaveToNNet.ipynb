{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from TL4HDR.data.preProcess import get_one_race, get_n_years, normalize_dataset, \\\n",
    "    standarize_dataset, get_dataset\n",
    "from TL4HDR.examples.classify_util import run_mixture_cv, run_one_race_cv, \\\n",
    "    run_unsupervised_transfer_cv, run_supervised_transfer_cv, run_CCSA_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(11111)\n",
    "set_random_seed(11111)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "rn.seed(11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(cancer_type, feature_type, target, years=3, groups=(\"WHITE\", \"BLACK\")):\n",
    "    print (cancer_type, feature_type, target, years)\n",
    "    # dataset = get_dataset_integ(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    dataset = get_dataset(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    if dataset['X'].shape[0] < 10: return None\n",
    "    dataset = standarize_dataset(dataset)\n",
    "    dataset_w = get_one_race(dataset, 'WHITE')\n",
    "    if dataset_w['X'].shape[0] < 5: return None\n",
    "    dataset_w = get_n_years(dataset_w, years)\n",
    "    dataset_b = get_one_race(dataset, 'BLACK')\n",
    "    if dataset_b['X'].shape[0] < 5: return None\n",
    "    dataset_b = get_n_years(dataset_b, years)\n",
    "\n",
    "    dataset_tl = normalize_dataset(dataset)\n",
    "    dataset_tl = get_n_years(dataset_tl, years)\n",
    "\n",
    "    dataset = get_n_years(dataset, years)\n",
    "    k = 200 if 'mRNA' in feature_type or 'methylation' in feature_type else -1\n",
    "\n",
    "    # print(numpy.count_nonzero(numpy.isnan(dataset['X'])))\n",
    "    X, Y, R, y_sub, y_strat = dataset\n",
    "    df = pd.DataFrame(y_strat, columns=['RY'])\n",
    "    df['R'] = R\n",
    "    df['Y'] = Y\n",
    "    print(X.shape)\n",
    "    Dict = df['RY'].value_counts()\n",
    "    print (Dict)\n",
    "    if len(Dict) < 4: return None\n",
    "    Dict = dict(Dict)\n",
    "    print (Dict)\n",
    "    for key in Dict:\n",
    "        print (key, Dict[key])\n",
    "        if Dict[key] < 5:\n",
    "            return None\n",
    "\n",
    "    parametrs_mix = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,'momentum':0.9,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_w = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_b = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':4,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "    parametrs_tl = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20, 'tune_epoch':500,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5, 'tune_lr':0.002,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64], 'tune_batch':10}\n",
    "\n",
    "    parametrs_tl_unsupervised = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.001, 'lr_decay':0.03, 'dropout':0.0, 'n_epochs':100,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [100]}\n",
    "\n",
    "    # parametrs_tl_sa = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "    #                  'learning_rate':0.005, 'lr_decay':0.0, 'dropout':0.5,\n",
    "    #                  'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "\n",
    "    parameters_CCSA = {'fold': 3, 'n_features': k, 'alpha':0.3, 'batch_size':32, 'learning_rate':0.01,\n",
    "                       'hidden_layers': [100], 'dr':0.0, 'momentum':0.0,\n",
    "                       'decay':0.0, 'sample_per_class':2}\n",
    "\n",
    "    print(\"Begin classifier training\")\n",
    "    \n",
    "    seed = 0\n",
    "    df_m, mixture_classifiers = run_mixture_cv(seed, dataset, **parametrs_mix)\n",
    "    df_w, w_classifiers = run_one_race_cv(seed, dataset_w, **parametrs_w)\n",
    "    df_w = df_w.rename(columns={\"Auc\": \"W_ind\"})\n",
    "    df_b, b_classifiers = run_one_race_cv(seed, dataset_b, **parametrs_b)\n",
    "    df_b = df_b.rename(columns={\"Auc\": \"B_ind\"})\n",
    "    \n",
    "    print(\"Supervised transfer\")\n",
    "    df_tl_supervised, supervised_transfer_classifiers = run_supervised_transfer_cv(seed, dataset, **parametrs_tl)\n",
    "    df_tl_supervised = df_tl_supervised.rename(columns={\"TL_Auc\": \"XY_TL\"})\n",
    "\n",
    "    print(\"Unsupervised transfer\")\n",
    "    df_tl_unsupervised, unsupervised_transfer_classifiers = run_unsupervised_transfer_cv(seed, dataset, **parametrs_tl_unsupervised)\n",
    "    df_tl_unsupervised = df_tl_unsupervised.rename(columns={\"TL_Auc\": \"X_TL\"})\n",
    "\n",
    "    print(\"CCSA transfer\")\n",
    "    df_tl, ccsa_transfer_models = run_CCSA_transfer(seed, dataset_tl, **parameters_CCSA)\n",
    "    df_tl = df_tl.rename(columns={\"TL_Auc\": \"CCSA_TL\"})\n",
    "\n",
    "    df1 = pd.concat([df_m, df_w['W_ind'], df_b['B_ind'], df_tl['CCSA_TL'],\n",
    "                    # df_tl_unsupervised['X_TL'],\n",
    "                     df_tl_supervised['XY_TL']],\n",
    "                    sort=False, axis=1)\n",
    "\n",
    "    print(df1)\n",
    "    \n",
    "    return mixture_classifiers, w_classifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BRCA', 'Protein', 'OS', 4)\n",
      "(811, 190)\n",
      "(810, 192)\n",
      "(322, 189)\n",
      "1WHITE    216\n",
      "0WHITE     57\n",
      "1BLACK     39\n",
      "0BLACK     10\n",
      "Name: RY, dtype: int64\n",
      "{'1BLACK': 39, '0WHITE': 57, '1WHITE': 216, '0BLACK': 10}\n",
      "('1BLACK', 39)\n",
      "('0WHITE', 57)\n",
      "('1WHITE', 216)\n",
      "('0BLACK', 10)\n",
      "Begin classifier training\n",
      "Supervised transfer\n",
      "Unsupervised transfer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TL4HDR/model/mlp.py:158: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(corruption_level, default=0.2),\n",
      "TL4HDR/model/mlp.py:159: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(learning_rate, default=0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSA transfer\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 100)          19000       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_1[0][0]                  \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3fc536fee8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmixture_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervised_transfer_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsupervised_transfer_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mccsa_transfer_models\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mrun_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BRCA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Protein'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4a6c26e42709>\u001b[0m in \u001b[0;36mrun_cv\u001b[0;34m(cancer_type, feature_type, target, years, groups)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CCSA transfer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mdf_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mccsa_transfer_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_CCSA_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters_CCSA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mdf_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"TL_Auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"CCSA_TL\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingshyanku/nn-verification/TL4HDR/examples/classify_util.pyc\u001b[0m in \u001b[0;36mrun_CCSA_transfer\u001b[0;34m(seed, dataset, n_features, fold, alpha, learning_rate, hidden_layers, dr, groups, momentum, decay, batch_size, sample_per_class, repetition)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                                      \u001b[0mrepetition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepetition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                                      n_features=n_features)\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingshyanku/nn-verification/TL4HDR/examples/classify_util.pyc\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m(X_train_target, y_train_target, X_train_source, y_train_source, X_val_target, Y_val_target, X_test, y_test, repetition, sample_per_class, alpha, learning_rate, hidden_layers, dr, momentum, decay, batch_size, n_features)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m#plot the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     plot_model(model, to_file='model_plot.png', show_shapes = True,\n\u001b[0;32m--> 285\u001b[0;31m     show_layer_names = True)\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     print('Best AUC for {} target sample per class and repetition {} is {}.'.format(sample_per_class,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/utils/vis_utils.pyc\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         raise OSError(\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "mixture_classifiers, w_classifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models \\\n",
    "    = run_cv('BRCA', 'Protein', 'OS', years=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNet.utils.writeNNet import writeNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield layer.W.get_value()\n",
    "\n",
    "\n",
    "def get_biases(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield layer.b.get_value()\n",
    "\n",
    "\n",
    "def save_classifier(classifier, file_path):\n",
    "    weights = list(get_weights(classifier))\n",
    "    biases = list(get_biases(classifier))\n",
    "    num_inputs = weights[0].shape[1]\n",
    "\n",
    "    input_mins = [-1 for _ in range(num_inputs)]\n",
    "    input_maxes = [1 for _ in range(num_inputs)]\n",
    "    input_ranges = [2 for _ in range(num_inputs)] + [1] # 1 scales output\n",
    "    input_means = [0 for _ in range(num_inputs + 1)] + [0] # 0 added to output\n",
    "\n",
    "    writeNNet(weights, biases, input_mins, input_maxes, input_means, input_ranges, file_path)\n",
    "\n",
    "\n",
    "def save_classifiers(classifiers, file_path_prefix):\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        save_classifier(classifier, file_path_prefix + str(i) + \".nnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifiers(mixture_classifiers, \"TL4HDR/Result/mixture_\")\n",
    "save_classifiers(w_classifiers, \"TL4HDR/Result/w_\")\n",
    "save_classifiers(b_classifiers, \"TL4HDR/Result/w_\")\n",
    "save_classifiers(supervised_transfer_classifiers, \"TL4HDR/Result/supervised_transfer_\")\n",
    "save_classifiers(unsupervised_transfer_classifiers, \"TL4HDR/Result/unsupervised_transfer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path):\n",
    "    model.save(file_path)\n",
    "\n",
    "\n",
    "def save_models(models, file_path_prefix):\n",
    "    for i, model in enumerate(models):\n",
    "        save_model(model, file_path_prefix + str(i) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(ccsa_transfer_models, \"TL4HDR/Result/ccsa_transfer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MarabouRepo.maraboupy import Marabou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(models):\n",
    "    for layer in model.layers:\n",
    "        weights = list(layer.get_weights()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
