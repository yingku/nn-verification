{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from TL4HDR.data.preProcess import get_one_race, get_n_years, normalize_dataset, \\\n",
    "    standarize_dataset, get_dataset\n",
    "from TL4HDR.examples.classify_util import run_mixture_cv, run_one_race_cv, \\\n",
    "    run_unsupervised_transfer_cv, run_supervised_transfer_cv, run_CCSA_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(11111)\n",
    "set_random_seed(11111)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "rn.seed(11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(cancer_type, feature_type, target, years=3, groups=(\"WHITE\", \"BLACK\")):\n",
    "    print (cancer_type, feature_type, target, years)\n",
    "    # dataset = get_dataset_integ(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    dataset = get_dataset(cancer_type=cancer_type, feature_type=feature_type, target=target, groups=groups)\n",
    "    if dataset['X'].shape[0] < 10: return None\n",
    "    dataset = standarize_dataset(dataset)\n",
    "    dataset_w = get_one_race(dataset, 'WHITE')\n",
    "    if dataset_w['X'].shape[0] < 5: return None\n",
    "    dataset_w = get_n_years(dataset_w, years)\n",
    "    dataset_b = get_one_race(dataset, 'BLACK')\n",
    "    if dataset_b['X'].shape[0] < 5: return None\n",
    "    dataset_b = get_n_years(dataset_b, years)\n",
    "\n",
    "    dataset_tl = normalize_dataset(dataset)\n",
    "    dataset_tl = get_n_years(dataset_tl, years)\n",
    "\n",
    "    dataset = get_n_years(dataset, years)\n",
    "    k = 200 if 'mRNA' in feature_type or 'methylation' in feature_type else -1\n",
    "\n",
    "    # print(numpy.count_nonzero(numpy.isnan(dataset['X'])))\n",
    "    X, Y, R, y_sub, y_strat = dataset\n",
    "    df = pd.DataFrame(y_strat, columns=['RY'])\n",
    "    df['R'] = R\n",
    "    df['Y'] = Y\n",
    "    print(X.shape)\n",
    "    Dict = df['RY'].value_counts()\n",
    "    print (Dict)\n",
    "    if len(Dict) < 4: return None\n",
    "    Dict = dict(Dict)\n",
    "    print (Dict)\n",
    "    for key in Dict:\n",
    "        print (key, Dict[key])\n",
    "        if Dict[key] < 5:\n",
    "            return None\n",
    "\n",
    "    parametrs_mix = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,'momentum':0.9,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_w = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "    parametrs_b = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':4,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.0, 'dropout':0.5,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "    parametrs_tl = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20, 'tune_epoch':500,\n",
    "                     'learning_rate':0.01, 'lr_decay':0.03, 'dropout':0.5, 'tune_lr':0.002,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64], 'tune_batch':10}\n",
    "\n",
    "    parametrs_tl_unsupervised = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "                     'learning_rate':0.001, 'lr_decay':0.03, 'dropout':0.0, 'n_epochs':100,\n",
    "                     'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [100]}\n",
    "\n",
    "    # parametrs_tl_sa = {'fold': 3, 'k': k, 'val_size':0.0, 'batch_size':20,\n",
    "    #                  'learning_rate':0.005, 'lr_decay':0.0, 'dropout':0.5,\n",
    "    #                  'L1_reg': 0.001, 'L2_reg': 0.001, 'hidden_layers': [128, 64]}\n",
    "\n",
    "\n",
    "    parameters_CCSA = {'fold': 3, 'n_features': k, 'alpha':0.3, 'batch_size':32, 'learning_rate':0.01,\n",
    "                       'hidden_layers': [100], 'dr':0.0, 'momentum':0.0,\n",
    "                       'decay':0.0, 'sample_per_class':2}\n",
    "\n",
    "    print(\"Begin classifier training\")\n",
    "    \n",
    "    seed = 0\n",
    "    df_m, mixture_classifiers = run_mixture_cv(seed, dataset, **parametrs_mix)\n",
    "    df_w, w_classifiers = run_one_race_cv(seed, dataset_w, **parametrs_w)\n",
    "    df_w = df_w.rename(columns={\"Auc\": \"W_ind\"})\n",
    "    df_b, b_classifiers = run_one_race_cv(seed, dataset_b, **parametrs_b)\n",
    "    df_b = df_b.rename(columns={\"Auc\": \"B_ind\"})\n",
    "    \n",
    "    print(\"Supervised transfer\")\n",
    "    df_tl_supervised, supervised_transfer_classifiers = run_supervised_transfer_cv(seed, dataset, **parametrs_tl)\n",
    "    df_tl_supervised = df_tl_supervised.rename(columns={\"TL_Auc\": \"XY_TL\"})\n",
    "\n",
    "    print(\"Unsupervised transfer\")\n",
    "    df_tl_unsupervised, unsupervised_transfer_classifiers = run_unsupervised_transfer_cv(seed, dataset, **parametrs_tl_unsupervised)\n",
    "    df_tl_unsupervised = df_tl_unsupervised.rename(columns={\"TL_Auc\": \"X_TL\"})\n",
    "\n",
    "    print(\"CCSA transfer\")\n",
    "    df_tl, ccsa_transfer_models = run_CCSA_transfer(seed, dataset_tl, **parameters_CCSA)\n",
    "    df_tl = df_tl.rename(columns={\"TL_Auc\": \"CCSA_TL\"})\n",
    "\n",
    "    df1 = pd.concat([df_m, df_w['W_ind'], df_b['B_ind'], df_tl['CCSA_TL'],\n",
    "                    # df_tl_unsupervised['X_TL'],\n",
    "                     df_tl_supervised['XY_TL']],\n",
    "                    sort=False, axis=1)\n",
    "\n",
    "    print(df1)\n",
    "    \n",
    "    return mixture_classifiers, w_classifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BRCA', 'Protein', 'OS', 4)\n",
      "(811, 190)\n",
      "(810, 192)\n",
      "(322, 189)\n",
      "1WHITE    216\n",
      "0WHITE     57\n",
      "1BLACK     39\n",
      "0BLACK     10\n",
      "Name: RY, dtype: int64\n",
      "{'1BLACK': 39, '0WHITE': 57, '1WHITE': 216, '0BLACK': 10}\n",
      "('1BLACK', 39)\n",
      "('0WHITE', 57)\n",
      "('1WHITE', 216)\n",
      "('0BLACK', 10)\n",
      "Begin classifier training\n",
      "Supervised transfer\n",
      "Unsupervised transfer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TL4HDR/model/mlp.py:158: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(corruption_level, default=0.2),\n",
      "TL4HDR/model/mlp.py:159: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  theano.Param(learning_rate, default=0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSA transfer\n",
      "WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 100)          19000       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_1[0][0]                  \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.596153846154.\n",
      "(17,)\n",
      "(17,)\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 100)          19000       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            202         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_2[0][0]                  \n",
      "                                                                 sequential_2[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.358974358974.\n",
      "(16,)\n",
      "(16,)\n",
      "Domain Adaptation Task: WHITE_to_BLACK\n",
      "Creating pairs for repetition: 1 and sample_per_class: 2\n",
      "('Training the model - Epoch 100', ' total trainings:', (1092, 189), (1092, 189))\n",
      "0->10->20->30->40->50->60->70->80->90->99\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 100)          19000       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 189)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            202         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Activation)     (None, 2)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "CSA (Lambda)                    (None, 1)            0           dropout_3[0][0]                  \n",
      "                                                                 sequential_3[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,202\n",
      "Trainable params: 19,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Best AUC for 2 target sample per class and repetition 1 is 0.589743589744.\n",
      "(16,)\n",
      "(16,)\n",
      "     A_Auc     B_Auc     W_Auc  folds     W_ind     B_ind   CCSA_TL    XY_TL\n",
      "0  0.70559  0.479487  0.746914      3  0.759422  0.571795  0.458974  0.54359\n"
     ]
    }
   ],
   "source": [
    "mixture_classifiers, w_classifiers, b_classifiers, supervised_transfer_classifiers, unsupervised_transfer_classifiers, ccsa_transfer_models \\\n",
    "    = run_cv('BRCA', 'Protein', 'OS', years=4)\n",
    "# mixture_classifiers = run_cv('BRCA', 'Protein', 'OS', years=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNet.utils.writeNNet import writeNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield np.transpose(layer.W.get_value())\n",
    "\n",
    "\n",
    "def get_biases(classifier):\n",
    "    for layer in classifier.hidden_layers:\n",
    "        yield layer.b.get_value()\n",
    "\n",
    "\n",
    "def save_classifier(classifier, file_path):\n",
    "    weights = list(get_weights(classifier))\n",
    "    biases = list(get_biases(classifier))\n",
    "    num_inputs = weights[0].shape[1]\n",
    "    \n",
    "    print(list(map(lambda a: len(a), weights)))\n",
    "    print(list(map(lambda a: len(a), biases)))\n",
    "\n",
    "    input_mins = [-1 for _ in range(num_inputs)]\n",
    "    input_maxes = [1 for _ in range(num_inputs)]\n",
    "    input_ranges = [2 for _ in range(num_inputs)] + [1] # 1 scales output\n",
    "    input_means = [0 for _ in range(num_inputs + 1)] + [0] # 0 added to output\n",
    "\n",
    "    writeNNet(weights, biases, input_mins, input_maxes, input_means, input_ranges, file_path)\n",
    "\n",
    "\n",
    "def save_classifiers(classifiers, file_path_prefix):\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        save_classifier(classifier, file_path_prefix + str(i) + \".nnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[128, 64]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "save_classifiers(mixture_classifiers, \"TL4HDR/Result/mixture_\")\n",
    "save_classifiers(w_classifiers, \"TL4HDR/Result/w_\")\n",
    "save_classifiers(b_classifiers, \"TL4HDR/Result/w_\")\n",
    "save_classifiers(supervised_transfer_classifiers, \"TL4HDR/Result/supervised_transfer_\")\n",
    "save_classifiers(unsupervised_transfer_classifiers, \"TL4HDR/Result/unsupervised_transfer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keras(model, file_path):\n",
    "    # Get a list of the model weights\n",
    "    model_params = model.get_weights()\n",
    "\n",
    "    # Split the network parameters into weights and biases, assuming they alternate\n",
    "    weights = model_params[0:len(model_params):2]\n",
    "    biases  = model_params[1:len(model_params):2]\n",
    "\n",
    "    # Transpose weight matrices\n",
    "    weights = [w.T for w in weights]\n",
    "    \n",
    "    # Get num inputs\n",
    "    num_inputs = weights[0].shape[1]\n",
    "\n",
    "    # Min and max values used to bound the inputs\n",
    "    input_mins  = [-1 for _ in range(num_inputs)]\n",
    "    input_maxes = [1 for _ in range(num_inputs)]\n",
    "\n",
    "    # Mean and range values for normalizing the inputs and outputs. All outputs are normalized with the same value\n",
    "    means  = [0 for _ in range(num_inputs + 1)] + [0]\n",
    "    ranges = [2 for _ in range(num_inputs)] + [1]\n",
    "\n",
    "    # Convert the file\n",
    "    writeNNet(weights,biases,input_mins,input_maxes,means,ranges,file_path)\n",
    "\n",
    "    \n",
    "def save_kerases(models, file_path_prefix):\n",
    "    for i, model in enumerate(models):\n",
    "        save_keras(model, file_path_prefix + str(i) + \".model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_kerases(ccsa_transfer_models, \"TL4HDR/Result/ccsa_transfer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nathan/Programming/python/nn-verification/venv/lib/python2.7/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MarabouRepo/maraboupy/Marabou.py:31: UserWarning: ONNX parser is unavailable because onnx or onnxruntime packages are not installed\n",
      "  warnings.warn(\"ONNX parser is unavailable because onnx or onnxruntime packages are not installed\")\n"
     ]
    }
   ],
   "source": [
    "from MarabouRepo.maraboupy import Marabou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat\n",
      "input 0 = -0.5\n",
      "input 1 = -0.5\n",
      "input 2 = -0.5\n",
      "input 3 = -0.5\n",
      "input 4 = -0.5\n",
      "input 5 = -0.5\n",
      "input 6 = -0.5\n",
      "input 7 = -0.5\n",
      "input 8 = -0.5\n",
      "input 9 = -0.5\n",
      "input 10 = -0.5\n",
      "input 11 = -0.5\n",
      "input 12 = -0.5\n",
      "input 13 = -0.5\n",
      "input 14 = -0.5\n",
      "input 15 = 0.5\n",
      "input 16 = -0.5\n",
      "input 17 = -0.5\n",
      "input 18 = -0.5\n",
      "input 19 = -0.5\n",
      "input 20 = -0.5\n",
      "input 21 = -0.5\n",
      "input 22 = -0.5\n",
      "input 23 = -0.5\n",
      "input 24 = -0.00617805289676\n",
      "input 25 = -0.5\n",
      "input 26 = -0.5\n",
      "input 27 = -0.5\n",
      "input 28 = 0.160021926317\n",
      "input 29 = -0.5\n",
      "input 30 = -0.5\n",
      "input 31 = -0.5\n",
      "input 32 = -0.5\n",
      "input 33 = -0.5\n",
      "input 34 = -0.5\n",
      "input 35 = -0.5\n",
      "input 36 = -0.5\n",
      "input 37 = -0.5\n",
      "input 38 = -0.5\n",
      "input 39 = -0.5\n",
      "input 40 = -0.5\n",
      "input 41 = -0.5\n",
      "input 42 = -0.5\n",
      "input 43 = -0.5\n",
      "input 44 = -0.5\n",
      "input 45 = -0.101392885351\n",
      "input 46 = -0.5\n",
      "input 47 = -0.5\n",
      "input 48 = -0.5\n",
      "input 49 = -0.5\n",
      "input 50 = -0.131106159845\n",
      "input 51 = -0.5\n",
      "input 52 = -0.5\n",
      "input 53 = -0.5\n",
      "input 54 = -0.384522696888\n",
      "input 55 = -0.5\n",
      "input 56 = 0.0749539196571\n",
      "input 57 = -0.130857231349\n",
      "input 58 = -0.399938191867\n",
      "input 59 = -0.5\n",
      "input 60 = -0.5\n",
      "input 61 = -0.5\n",
      "input 62 = -0.5\n",
      "input 63 = -0.5\n",
      "input 64 = -0.5\n",
      "input 65 = -0.341602244327\n",
      "input 66 = -0.5\n",
      "input 67 = -0.5\n",
      "input 68 = -0.181840495639\n",
      "input 69 = -0.5\n",
      "input 70 = 0.5\n",
      "input 71 = -0.5\n",
      "input 72 = -0.5\n",
      "input 73 = -0.5\n",
      "input 74 = -0.5\n",
      "input 75 = 0.305424229569\n",
      "input 76 = -0.5\n",
      "input 77 = -0.5\n",
      "input 78 = -0.5\n",
      "input 79 = -0.5\n",
      "input 80 = -0.5\n",
      "input 81 = -0.5\n",
      "input 82 = -0.5\n",
      "input 83 = 0.188367689603\n",
      "input 84 = -0.5\n",
      "input 85 = -0.5\n",
      "input 86 = -0.5\n",
      "input 87 = -0.5\n",
      "input 88 = -0.5\n",
      "input 89 = -0.5\n",
      "input 90 = 0.26354163927\n",
      "input 91 = -0.5\n",
      "input 92 = -0.5\n",
      "input 93 = -0.5\n",
      "input 94 = -0.5\n",
      "input 95 = -0.5\n",
      "input 96 = -0.5\n",
      "input 97 = -0.5\n",
      "input 98 = 0.5\n",
      "input 99 = -0.5\n",
      "input 100 = -0.5\n",
      "input 101 = -0.5\n",
      "input 102 = -0.5\n",
      "input 103 = -0.5\n",
      "input 104 = -0.5\n",
      "input 105 = -0.5\n",
      "input 106 = -0.5\n",
      "input 107 = -0.5\n",
      "input 108 = -0.132599165474\n",
      "input 109 = 0.222173866436\n",
      "input 110 = -0.5\n",
      "input 111 = -0.5\n",
      "input 112 = -0.5\n",
      "input 113 = -0.5\n",
      "input 114 = -0.5\n",
      "input 115 = -0.5\n",
      "input 116 = -0.5\n",
      "input 117 = -0.5\n",
      "input 118 = -0.5\n",
      "input 119 = -0.5\n",
      "input 120 = -0.5\n",
      "input 121 = -0.5\n",
      "input 122 = -0.5\n",
      "input 123 = -0.5\n",
      "input 124 = -0.5\n",
      "input 125 = 0.358782827743\n",
      "input 126 = -0.5\n",
      "input 127 = -0.5\n",
      "input 128 = -0.5\n",
      "input 129 = -0.5\n",
      "input 130 = -0.5\n",
      "input 131 = -0.5\n",
      "input 132 = -0.5\n",
      "input 133 = -0.5\n",
      "input 134 = -0.5\n",
      "input 135 = -0.5\n",
      "input 136 = -0.5\n",
      "input 137 = -0.5\n",
      "input 138 = -0.5\n",
      "input 139 = -0.5\n",
      "input 140 = -0.5\n",
      "input 141 = -0.5\n",
      "input 142 = -0.5\n",
      "input 143 = -0.5\n",
      "input 144 = -0.5\n",
      "input 145 = -0.5\n",
      "input 146 = -0.5\n",
      "input 147 = -0.5\n",
      "input 148 = -0.5\n",
      "input 149 = -0.5\n",
      "input 150 = -0.5\n",
      "input 151 = -0.5\n",
      "input 152 = -0.5\n",
      "input 153 = -0.5\n",
      "input 154 = -0.5\n",
      "input 155 = -0.5\n",
      "input 156 = -0.5\n",
      "input 157 = -0.5\n",
      "input 158 = -0.5\n",
      "input 159 = -0.5\n",
      "input 160 = -0.5\n",
      "input 161 = -0.5\n",
      "input 162 = -0.360187997233\n",
      "input 163 = -0.5\n",
      "input 164 = -0.5\n",
      "input 165 = -0.5\n",
      "input 166 = -0.5\n",
      "input 167 = -0.5\n",
      "input 168 = -0.5\n",
      "input 169 = -0.5\n",
      "input 170 = -0.5\n",
      "input 171 = -0.5\n",
      "input 172 = -0.5\n",
      "input 173 = -0.5\n",
      "input 174 = -0.5\n",
      "input 175 = -0.5\n",
      "input 176 = -0.5\n",
      "input 177 = -0.381442759963\n",
      "input 178 = -0.5\n",
      "input 179 = -0.5\n",
      "input 180 = -0.5\n",
      "input 181 = -0.5\n",
      "input 182 = -0.5\n",
      "input 183 = -0.5\n",
      "input 184 = -0.5\n",
      "input 185 = -0.5\n",
      "input 186 = -0.5\n",
      "input 187 = -0.183264560925\n",
      "input 188 = -0.5\n",
      "output 0 = 0.5\n",
      "output 1 = -0.64196248057\n"
     ]
    }
   ],
   "source": [
    "net1 = Marabou.read_nnet(\"TL4HDR/Result/ccsa_transfer_0.model\")\n",
    "net1.setLowerBound(net1.outputVars[0][0][0], .5)\n",
    "\n",
    "exitCode, vals1, stats1 = net1.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0           1            2            3            4    \\\n",
      "count  2000.000000  2000.00000  2000.000000  2000.000000  2000.000000   \n",
      "mean      0.097000     0.10100     0.110000     0.102000     0.092000   \n",
      "std       0.343001     0.33594     0.371442     0.338605     0.320293   \n",
      "min       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
      "max       4.000000     3.00000     4.000000     3.000000     3.000000   \n",
      "\n",
      "               5            6            7            8            9    ...  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
      "mean      0.103000     0.095500     0.099000     0.102000     0.116500  ...   \n",
      "std       0.335332     0.323159     0.340965     0.332643     0.367417  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "max       3.000000     3.000000     3.000000     2.000000     4.000000  ...   \n",
      "\n",
      "               190          191          192          193          194  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
      "mean      0.095500     0.085000     0.100500     0.106000     0.104500   \n",
      "std       0.315324     0.312768     0.335345     0.332895     0.325012   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       2.000000     3.000000     3.000000     3.000000     2.000000   \n",
      "\n",
      "               195          196          197          198          199  \n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  \n",
      "mean      0.097500     0.097500     0.106000     0.108500     0.098500  \n",
      "std       0.345041     0.327181     0.346156     0.356077     0.337424  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "max       3.000000     3.000000     4.000000     3.000000     4.000000  \n",
      "\n",
      "[8 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = 'TL4HDR/simulation/PanGyn-DFI-5-base.mat'\n",
    "A = loadmat(path)\n",
    "data = A['data']\n",
    "de = data['de'][0][0]\n",
    "de = np.squeeze(de)\n",
    "group = data['group'][0][0]\n",
    "group = np.squeeze(group) - 1\n",
    "counts = data['counts'][0][0]\n",
    "counts = counts.transpose()\n",
    "nGenes = counts.shape[1]\n",
    "df = pd.DataFrame(counts, columns=range(nGenes))\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  190  191  192  193  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  0.0  0.0  1.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
      "4  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
      "\n",
      "   194  195  196  197  198  199  \n",
      "0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
